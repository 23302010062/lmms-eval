task: geometry3k
dataset_path: parquet
dataset_kwargs:
  data_files: hf://datasets/kkv233/lmms-eval-dataset/geometry3k/geometry3k_train_first100.parquet
test_split: train
output_type: generate_until
doc_to_visual: !function utils.geometry3k_doc_to_visual
doc_to_text: !function utils.geometry3k_doc_to_text
doc_to_target: !function utils.geometry3k_doc_to_target
process_results: !function utils.geometry3k_process_results
generation_kwargs:
  max_new_tokens: 16384
  temperature: 0.0
  do_sample: false
metric_list:
  - metric: geometry3k_accuracy
    aggregation: !function utils.geometry3k_aggregate
    higher_is_better: true
metadata:
  version: 1.0
  description: "Geometry3K plane geometry dataset with 3,002 problems. Evaluation uses GPT-5.1 Judge for answer equivalence checking."
